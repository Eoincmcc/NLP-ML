{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-Retrieval Conversational Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR-QuAC is an aggregation of 3 different datasets:\n",
    "- QuAC\n",
    "- CANARD\n",
    "- Wiki-corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Packages\n",
    "\n",
    "- `faiss`\n",
    "    - Facebook AI Similarity Search\n",
    "- `pickle`\n",
    "    - 'Pickles' a python object to a byte stream\n",
    "- `tqdm`\n",
    "    - Progress bar\n",
    "- `pytrec_eval`\n",
    "    - Python Interface fro TREC's Evaluation tool.\n",
    "    - `TReC` is the Text Retrieval Conference with the tool used to standardise results evaluation\n",
    "- `torch`\n",
    "    - PyTorch package containing data-structures for multi-dimensional `tensors` (matrices) \n",
    "    - Used for math operations on matrices, and other utilities\n",
    "- from `torch.utils.data`\n",
    "    - `DataLoader`\n",
    "        - Combines Dataset and Sampler, provides iterable over given dataset\n",
    "    - Samplers: `RandomSampler`, `SequentialSampler`\n",
    "- from `torch.utils.data.distributed`\n",
    "    - `DistributedSampler`\n",
    "        - Restricts data loading to subset of data\n",
    "- `Tensorboard`\n",
    "    - Provides Measurements and Visualisations needed during machine learning workflow\n",
    "    - Tracks experiment metrics, visualises model graphs, projects embeddings into lower space etc.\n",
    "- from `torch.utils.tensorboard`\n",
    "    - `SummaryWriter`\n",
    "        - Used to create a writer which is a data log that can be consumed and visualised by TensorBoard.\n",
    "- `transformers`\n",
    "    - library of pre-trained transformer models\n",
    "- from `transformers`\n",
    "    - Imports const `WEIGHTS_NAME` defined in the package as \"pytorch_model.bin\"\n",
    "    - 2 Model Configuration Classes\n",
    "        - Config Classes are used to store the configuration of models.\n",
    "        - They instantiate the chosen models according to specified arguments on initialisation.\n",
    "        - Arguments will most likely differ between models and uses?  \n",
    "        - They inherit from `PretrainedConfig`\n",
    "        - `BertConfig` is imported to create BERT models\n",
    "        - `AlbertConfig` is also imported\n",
    "    - 2 corresponding `Tokenizer` classes are also imported and used to construct tokenizers for the models\n",
    "        - Tokenizers based on `WordPiece`\n",
    "        - `BertTokenizer` and `AlbertTokenizer` imported.\n",
    "    - `AdamW`\n",
    "        - Adam Weight Decay\n",
    "        - Adam is an algorithm used to optimise stochastic gradient descent functions.\n",
    "        - Weight Decay is a regularisation technique that adds a small penalty to the loss function.\n",
    "            - The loss added is usually the L2 norm of the weights.\n",
    "            - Regularisation using this technique prevents over-fitting and avoids the exploding gradient problem.\n",
    "        - [More here](https://medium.com/analytics-vidhya/deep-learning-basics-weight-decay-3c68eb4344e9)\n",
    "    - `get_linear_schedule_with_warmup` \n",
    "        - Creates a schedule with a learning rate that increases linearly from 0 to a defined peak rate before decreasing linearly back to 0.\n",
    "- from `utils`\n",
    "    - utils is an included class that is part of the paper.\n",
    "    - Methods are not well documented\n",
    "    - `LazyQuacDatasetGlobal`\n",
    "        -  Alternative training mode??\n",
    "    - `RawResult` \n",
    "        - Used for ranking?\n",
    "    - `write_predictions`\n",
    "        - Logger comment in code states: \n",
    "            > Write final predictions to the json file and log-odds of null if needed.\n",
    "    - `write_final_predictions`\n",
    "        - Converts instance level predictions to quac predictions\n",
    "        - Writes final predictions to file\n",
    "    - `get_retrieval_metrics`\n",
    "        - Returns dictionary of retrieval metrics\n",
    "    - `gen_reader_features`\n",
    "        - Not sure what reader features are\n",
    "- from `retriever_utils`\n",
    "    - File written by paper author with multiple classes\n",
    "    - `RetrieverDataset`\n",
    "        - class to set up dataset used in retrieval\n",
    "- from `modeling`\n",
    "    - Authors file for setting up BERT, AlBERT models\n",
    "    - `pipeline`\n",
    "        - pipeline init class\n",
    "    - `AlbertForRetrieverOnlyPositivePassage`\n",
    "        - Class contains initialisation methods and methods for training\n",
    "    - `BertForOrconvqaGlobal`\n",
    "        - Initialises, Trains BERT model used for ORConvQA\n",
    "         \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awful structure in researcher jupyter files, significant amount of code lines at zero indentation should be run in functions or with the dozens of `parser.add_argument` should simply not be there at all. <br>\n",
    "A config file isn't a crime.\n",
    "\n",
    "Code also references multiple versions of the transformers library where some functionality has been deprecated\n",
    "\n",
    "Needed to remove edit Utils to fix imports.\n",
    "Author has been importing functions one by one from a class when it's redundant beyond simply importing the relevant classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block one\n",
    "Set up logger files \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1c2bba4f3e42b796334fe51b77d8c6a8543e2302369e6536b4439c39780ff1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('shims': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
